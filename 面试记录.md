---
title: 面试记录 
tags: 面试
grammar_cjkRuby: true
---

# java 知识
## 多线程相关

### 线程池有几种创建方法

```
//创建固定数量线程的线程池
//创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待
ExecutorService es=Executors.newFixedThreadPool(2);

//创建单线程的线程池
//创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行
ExecutorService es=Executors.newSingleThreadExecutor();

//创建定时线程
//创建一个定长线程池，支持定时及周期性任务执行
ScheduledExecutorService es=Executors.newScheduledThreadPool(2);

//创建一个可缓存线程池
//创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程
 ExecutorService cachedThreadPool = Executors.newCachedThreadPool();
 
//创建单个定时线程池
//线程池只有一个工作线程，它能干时间计划来执行任务
 ExecutorService cachedThreadPool = Executors.newSingleThreadScheduleExecutor();
```
### 线程同步几种方法
1.同步方法
```
public synchronized void save(){}
```
2.同步代码块
```
synchronized(object){ 
}
```
3.使用特殊域变量(volatile)实现线程同步
 - volatile关键字为域变量的访问提供了一种免锁机制
 - 使用volatile修饰域相当于告诉虚拟机该域可能会被其他线程更新
 - 因此每次使用该域就要重新计算，而不是使用寄存器中的值
 - volatile不会提供任何原子操作，它也不能用来修饰final类型的变量
```java
class Bank {
    //需要同步的变量加上volatile
    private volatile int account = 100;

    public int getAccount() {
        return account;
    }
    //这里不再需要synchronized 
    public void save(int money) {
        account += money;
    }
｝

```
4.使用重入锁实现线程同步

 - 最好两个都不用，使用一种java.util.concurrent包提供的机制，能够帮助用户处理所有与锁相关的代码

 - 如果synchronized关键字能满足用户的需求，就用synchronized，因为它能简化代码

 - 如果需要更高级的功能，就用ReentrantLock类，此时要注意及时释放锁，否则会出现死锁，通常在finally代码释放锁
```
class Bank {
    private int account = 100;
    //需要声明这个锁
    private Lock lock = new ReentrantLock();
    public int getAccount() {
        return account;
    }
    //这里不再需要synchronized 
    public void save(int money) {
        lock.lock();
        try{
            account += money;
        }finally{
            lock.unlock();
        }
    }
｝
```

### 线程启动有几种方式

1.继承Thread类创建线程类

2.通过Runable接口创建线程类

3.通过Callable和FutureTask创建线程

4.通过线程池创建线程

### 线程池如何实现


## java 语言

### hashCode的生成算法
哈希算法可以将任意长度的二进制值引用为较短的且固定长度的二进制值，把这个小的二进制值称为哈希值。
```java
    public int hashCode() {
        int h = hash;
        if (h == 0 && count > 0) {
            int off = offset;
            char val[] = value;
            int len = count;


            for (int i = 0; i < len; i++) {
                h = 31*h + val[off++];
            }
            hash = h;
        }
        return h;
```
以cat为例:
也就是总共3次循环
第一次循环：h1=31*0+val[0]=val[0]='c'=99
第二次循环：h2=31*h1+val[1]=31*99+'a'=31*99+97=3166
第三次循环：h3=31*h2+val[2]=31*3166+'t'=31*3166+116=98262
所以cat的hashcode值为98262

### java 容器的实现原理

- ArrayList
1.ArrayList熟称动态数组；是一个不允许被序列化的对象数组
private transient Object[] elementData;

2.存储数据时是按照你插入的顺序进行存储的；用于存储一系列的对象引用(references)

3.由于实现了List接口，底层是通过数组实现的；

4.实现了RandomAccess接口支持随机访问访问该集合中的元素；
但是向集合中插入元素和删除集合中的元素耗时比较长，因为需要按照顺查找到目标元素进行相关操作；

5.初始容量：10
private static final int DEFAULT_CAPACITY = 10;

6.关于扩容：
```java
private static final int MAX_ARRAY_SIZE =   Integer.MAX_VALUE - 8;

private void grow(int minCapacity) {
        // overflow-conscious code
        int oldCapacity = elementData.length;
        //关键看这一步；通过位运算将其容量扩大了二倍；
      int newCapacity = oldCapacity + (oldCapacity >> 1);
        if (newCapacity - minCapacity < 0)
            newCapacity = minCapacity;
        if (newCapacity - MAX_ARRAY_SIZE > 0)
            newCapacity = hugeCapacity(minCapacity);
        // minCapacity is usually close to size, so this is a win:
        elementData = Arrays.copyOf(elementData, newCapacity);
}

private static int hugeCapacity(int minCapacity) {
        if (minCapacity < 0) // overflow
            throw new OutOfMemoryError();
        return (minCapacity > MAX_ARRAY_SIZE) ?
            Integer.MAX_VALUE :
            MAX_ARRAY_SIZE;
}
```

 - LinkedList

 1.基于链表实现，不支持随机访问，随机查询某个元素不如ArrayList；但是向集合中插入和删除元素缺比ArrayList性能好；不需要移动元素；
 
 2.存储数据是通过静态内部类Node；
``` java
private static class Node<E> {
        E item;
        Node<E> next;
        Node<E> prev;

        Node(Node<E> prev, E element, Node<E> next) {
            this.item = element;
            this.next = next;
            this.prev = prev;
        }
    }
```

- HashMap

它的底层是通过数组+链表+红黑树hashMap 的实例有两个参数影响其性能：初始容量 和加载因子

1.存储数据的格式:通过一个静态内部类Entry存储数据；

2.当链表长度大于8时会自动转换成红黑书

3.初始容量：16

### java反射机制（反射的应用场景）

1.xml 到 bean 的转换

2.JDBC 的数据库的连接通过Class.forName()加载数据库的驱动程序 （通过反射加载，前提是引入相关了Jar包）

3.使用反射机制，根据这个字符串获得某个类的Class实例

### 动态代理

### Object 类的方法有哪些

```
1.registerNativatives()
2.getClass()
3.hashCode()
4.equals(Object obj)
5.clone()
6.toString()
7.notify()
8.notifyAll()
9.wait(long timeout)
10.finalize()
线()
```
## Java 8 特性
### Java的新特性

 一、 Lambda表达式和函数式接口
 二、接口的默认方法和静态方法
 三、方法引用
 四、重复注释
 五、更好的类型推断
 六、注解的扩展

### Java编译器的新特性
一、参数名字

### Java  库的新特性
一、Optional
二、Stream
三、日期时间API
四、Nashorn javascript引擎
五、Base64
六、 并行数组
七、并发

### 新的工具
一、 Nashorn引擎：jjs
二、类依赖分析工具：jdeps
三、类依赖分析工具：jdeps

### JVM的新特性
JVM内存永久区已经被metaspace替换（JEP 122）。JVM参数 -XX:PermSize 和 –XX:MaxPermSize被XX:MetaSpaceSize 和 -XX:MaxMetaspaceSize代替

## java 异常分类

## java流


## JVM相关
### JVM结构

### 垃圾回收机制

### GC根对象
（1）虚拟机栈中引用的对象（栈帧中的本地变量表；

（2）方法区中的常量引用的对象；

（3）方法区中的类静态属性引用的对象；

（4）本地方法栈中JNI（Native方法）的引用对象。

（5）活跃线程。

### 垃圾回收算法

 1. 标记清除
 
 2. 标记整理

 3. 复制

 4. 分代回收

### 垃圾回收器
1、串行垃圾回收器     
串行垃圾回收器通过持有应用程序所有的线程进行工作。它为单线程环境设计，只使用一个单独的线程进行垃圾回收，通过冻结所有应用程序线程进行工作，所以可能不适合服务器环境。它最适合的是简单的命令行程序（单CPU、新生代空间较小及对暂停时间要求不是非常高的应用）。是client级别默认的GC方式。通过JVM参数-XX:+UseSerialGC可以使用串行垃圾回收器。

2、并行垃圾回收器     
并行垃圾回收器也叫做 throughput collector 。它是JVM的默认垃圾回收器。与串行垃圾回收器不同，它使用多线程进行垃圾回收。相似的是，当执行垃圾回收的时候它也会冻结所有的应用程序线程。适用于多CPU、对暂停时间要求较短的应用上，是server级别默认采用的GC方式。可用-XX:+UseParallelGC来强制指定，用-XX:ParallelGCThreads=4来指定线程数。

3、并发标记扫描垃圾回收器      
并发标记垃圾回收使用多线程扫描堆内存，标记需要清理的实例并且清理被标记过的实例。并发标记垃圾回收器只会在下面两种情况持有应用程序所有线程。
（1）当标记的引用对象在Tenured区域；
（2）在进行垃圾回收的时候，堆内存的数据被并发的改变。     
相比并行垃圾回收器，并发标记扫描垃圾回收器使用更多的CPU来确保程序的吞吐量。如果我们可以为了更好的程序性能分配更多的CPU，那么并发标记上扫描垃圾回收器是更好的选择相比并发垃圾回收器。通过JVM参数 XX:+USeParNewGC 打开并发标记扫描垃圾回收器。

4、G1收集器
G1收集器是当今收集器技术发展最前沿的成果，它是一款面向服务端应用的收集器，它能充分利用多CPU、多核环境。因此它是一款并行与并发收集器，并且它能建立可预测的停顿时间模型。      G1垃圾回收器适用于堆内存很大的情况，他将堆内存分割成不同的区域，并且并发的对其进行垃圾回收。G1也可以在回收内存之后对剩余的堆内存空间进行压缩。并发扫描标记垃圾回收器在STW情况下压缩内存。G1垃圾回收会优先选择第一块垃圾最多的区域。通过JVM参数 –XX:+UseG1GC 使用G1垃圾回收器。



以上各种GC机制是需要组合使用的，指定方式由下表所示：



### 垃圾回收执行时间和注意事项
GC分为Scavenge GC和Full GC。  

- Scavenge GC ：发生在Eden区的垃圾回收。

- Full GC :对整个堆进行整理，包括Young、Tenured和Perm。Full GC因为需要对整个堆进行回收，所以比Scavenge GC要慢，因此应该尽可能减少Full GC的次数。在对JVM调优的过程中，很大一部分工作就是对于FullGC的调节。    有如下原因可能导致Full GC：   
1.年老代（Tenured）被写满;   
2.持久代（Perm）被写满;   
3.System.gc()被显示调用;   
4.上一次GC之后Heap的各域分配策略动态变化

## 线程池如何实现



# 中间件
## zookeeper

## dubbo

## kafka
1.kafka依赖zookeeper
2.kafka 配置需要修改listeners=PLAINTEXT://192.168.1.155:9092
3.kafka 自定义序列化和反序列化

## redis
1.redis远程连接必须设置密码，本地连接可以不用设置密码。
2.redis后台启动要修改daemonize no 改为 daemonize yes
3.redis数据类型有5种，String， Hash，List，Set，Sorted Set

## mongodb

## rebbitmq

## EleasticSearch
1.ES元数据
document 文档 被Es转化为元数据：
index ---- 文档在哪存放
type  ---- 文档表示的对象类别
id ---- 文档唯一标识

相应体中相关数据：
_index 数据库
_type 表
_id 序号
_version 数据版本
_source 原数据

2.ES的refresh和flush的区别

![enter description here][1]
总结一下translog的功能：
1.保证在filesystem cache中的数据不会因为elasticsearch重启或是发生意外故障的时候丢失。
2.当系统重启时会从translog中恢复之前记录的操作。
3.当对elasticsearch进行CRUD操作的时候，会先到translog之中进行查找，因为tranlog之中保存的是最新的数据。
4.translog的清除时间时进行flush操作之后（将数据从filesystem cache刷入disk之中）

再总结一下flush操作的时间点：
1.es的各个shard会每个30分钟进行一次flush操作。
2.当translog的数据达到某个上限的时候会进行一次flush操作。

# 数据库
## mysql 锁
- 悲观锁
正如其名，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处 于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机 制，也无法保证外部系统不会修改数据）。
在悲观锁的情况下，为了保证事务的隔离性，就需要一致性锁定读。读取数据时给加锁，其它事务无法修改这些数据。修改删除数据时也要加锁，其它事务无法读取这些数据。

- 乐观锁
相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。
而乐观锁机制在一定程度上解决了这个问题。乐观锁，大多是基于数据版本（ Version ）记录机制实现。何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如 果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。

## mysql 查询优化
 -  explain 使用
 -  profiling 使用
1.开启 profiling 参数
   set profiling = 1 
 2.执行sql语句
 3.获取系统中保存所有query的profile概要信息
	show profiles;
 4.针对单个query获取详细的profile信息
	show profile cpu, block io for query 6（查询序号）

 - Waiting for table metadata lock 解决
1.mysql 查询正在执行事务进程id
	```
	select * from information_schema.innodb_trx
	```
2.杀死正在执行的SQL

	```
	kill $pid
	```

**开发中遇到mysql问题**
1.驱动表和被驱动表的关联字段类型不一致，在被驱动表中对建立的关联字段的索引在left join失效而inner join 确实有效的。

## mongodb
### mongodb 对象
|   SQL Terms/Concepts  | MongoDB Terms/Concepts    | 
| --- | --- | 
| database    |   database  |
| table  | collection  | 
| row |  document or BSON document  |
|   index   |     index   | 
| table joins | $lookup, embedded documents |
| primary key | primary key |
| aggregation | aggregation pipeline |
| transactions | transactions |

### mongodb 一些注意点

1.java代码的实体bean映射到mongodb中首字母要小写
例如 DataForReport 实体bean 映射到 mongodb 中 为 dataForReport

2.mongodb 做聚合查询时需要注意
$project 字段重命名功能
db.dataForReport.aggregate([{ $match: { useStatus: 1 } },{$group: {_id: "$washroomName", count: { $sum: 1 }}}, {"$project": {washroomName: "$_id","count": 1,"_id": 1}}])

java代码字段重命名
```java
Aggregation aggregation = Aggregation.newAggregation(
                Aggregation.match(Criteria.where("useStatus").is(1)),
                Aggregation.group("washroomName").count().as("total").first("washroomName").as("washroomName"),
                Aggregation.project("washroomName","total").andExclude("_id")
                );
AggregationResults<DataForReportModel> results = mongoTemplate.aggregate(aggregation, "dataForReport",   DataForReportModel.class);
 List<DataForReportModel> dataForReportModels = results.getMappedResults();
```
 3.mongodb 在做聚合时first和last作用
$first
Returns the value that results from applying an expression to the first document in a group of documents that share the same group by key. Only meaningful when documents are in a defined order.

# spring
## spring mvc 的注解

## bean 的作用域
1.singleton (spring 容器的默认值)
2.prototype
3.session
4.request
5.global session

## spring bean 循环依赖解决方案
Spring的循环依赖的理论依据其实是基于Java的引用传递，当我们获取到对象的引用时，对象的field或则属性是可以延后设置的(但是构造器必须是在获取引用之前)。
Spring的单例对象的初始化主要分为三步:
1.createBeanInstance：实例化，其实也就是调用对象的构造方法实例化对象
2.populateBean：填充属性，这一步主要是多bean的依赖属性进行填充
3.initializeBean：调用spring xml中的init 方法。
从上面讲述的单例bean初始化步骤我们可以知道，循环依赖主要发生在第一、第二部。也就是构造器循环依赖和field循环依赖。
那么我们要解决循环引用也应该从初始化过程着手，对于单例来说，在Spring容器整个生命周期内，有且只有一个对象，所以很容易想到这个对象应该存在Cache中，Spring为了解决单例的循环依赖问题，使用了三级缓存。
```java
/** Cache of singleton objects: bean name --> bean instance */
private final Map<String, Object> singletonObjects = new ConcurrentHashMap<String, Object>(256);

/** Cache of singleton factories: bean name --> ObjectFactory */
private final Map<String, ObjectFactory<?>> singletonFactories = new HashMap<String, ObjectFactory<?>>(16);

/** Cache of early singleton objects: bean name --> bean instance */
private final Map<String, Object> earlySingletonObjects = new HashMap<String, Object>(16);

```
这三级缓存分别指： 
singletonFactories ： 单例对象工厂的cache 
earlySingletonObjects ：提前暴光的单例对象的Cache 
singletonObjects：单例对象的cache
我们在创建bean的时候，首先想到的是从cache中获取这个单例的bean，这个缓存就是singletonObjects。主要调用方法就就是：
```java
protected Object getSingleton(String beanName, boolean allowEarlyReference) {
    Object singletonObject = this.singletonObjects.get(beanName);
    if (singletonObject == null && isSingletonCurrentlyInCreation(beanName)) {
        synchronized (this.singletonObjects) {
            singletonObject = this.earlySingletonObjects.get(beanName);
            if (singletonObject == null && allowEarlyReference) {
                ObjectFactory<?> singletonFactory = this.singletonFactories.get(beanName);
                if (singletonFactory != null) {
                    singletonObject = singletonFactory.getObject();
                    this.earlySingletonObjects.put(beanName, singletonObject);
                    this.singletonFactories.remove(beanName);
                }
            }
        }
    }
    return (singletonObject != NULL_OBJECT ? singletonObject : null);
}
```
首先解释两个参数：

 - isSingletonCurrentlyInCreation
 判断对应的单例对象是否在创建中，当单例对象没有被初始化完全(例如A定义的构造函数依赖了B对象，得先去创建B对象，或者在populatebean过程中依赖了B对象，得先去创建B对象，此时A处于创建中)
 - allowEarlyReference 是否允许从singletonFactories中通过getObject拿到对象

分析getSingleton的整个过程，Spring首先从singletonObjects（一级缓存）中尝试获取，如果获取不到并且对象在创建中，则尝试从earlySingletonObjects(二级缓存)中获取，如果还是获取不到并且允许从singletonFactories通过getObject获取，则通过singletonFactory.getObject()(三级缓存)获取。如果获取到了则
```java
this.earlySingletonObjects.put(beanName, singletonObject);
this.singletonFactories.remove(beanName);
```
则移除对应的singletonFactory,将singletonObject放入到earlySingletonObjects，其实就是将三级缓存提升到二级缓存中！

Spring解决循环依赖的诀窍就在于singletonFactories这个cache，这个cache中存的是类型为ObjectFactory，其定义如下：
```
public interface ObjectFactory<T> {
    T getObject() throws BeansException;}
```
在bean创建过程中，有两处比较重要的匿名内部类实现了该接口。一处是
```
new ObjectFactory<Object>() {
   @Override   public Object getObject() throws BeansException {
      try {
         return createBean(beanName, mbd, args);
      }      catch (BeansException ex) {
         destroySingleton(beanName);
         throw ex;
      }   }
```
在上文已经提到，Spring利用其创建bean（这样做真的很不明确呀...）
另一处就是:
``` java
addSingletonFactory(beanName, new ObjectFactory<Object>() {
   @Override   public Object getObject() throws BeansException {
      return getEarlyBeanReference(beanName, mbd, bean);
   }});
````
此处就是解决循环依赖的关键，这段代码发生在createBeanInstance之后，也就是说单例对象此时已经被创建出来的。这个对象已经被生产出来了，虽然还不完美（还没有进行初始化的第二步和第三步），但是已经能被人认出来了（根据对象引用能定位到堆中的对象），所以Spring此时将这个对象提前曝光出来让大家认识，让大家使用。

这样做有什么好处呢？让我们来分析一下“A的某个field或者setter依赖了B的实例对象，同时B的某个field或者setter依赖了A的实例对象”这种循环依赖的情况。A首先完成了初始化的第一步，并且将自己提前曝光到singletonFactories中，此时进行初始化的第二步，发现自己依赖对象B，此时就尝试去get(B)，发现B还没有被create，所以走create流程，B在初始化第一步的时候发现自己依赖了对象A，于是尝试get(A)，尝试一级缓存singletonObjects(肯定没有，因为A还没初始化完全)，尝试二级缓存earlySingletonObjects（也没有），尝试三级缓存singletonFactories，由于A通过ObjectFactory将自己提前曝光了，所以B能够通过ObjectFactory.getObject拿到A对象(虽然A还没有初始化完全，但是总比没有好呀)，B拿到A对象后顺利完成了初始化阶段1、2、3，完全初始化之后将自己放入到一级缓存singletonObjects中。此时返回A中，A此时能拿到B的对象顺利完成自己的初始化阶段2、3，最终A也完成了初始化，长大成人，进去了一级缓存singletonObjects中，而且更加幸运的是，由于B拿到了A的对象引用，所以B现在hold住的A对象也蜕变完美了！一切都是这么神奇！！

知道了这个原理时候，肯定就知道为啥Spring不能解决“A的构造方法中依赖了B的实例对象，同时B的构造方法中依赖了A的实例对象”这类问题了！


### spring 事务的传播机制
事务的第一个方面是传播行为。传播行为定义关于客户端和被调用方法的事务边界。Spring定义了7中传播行为。

| 传播行为                  | 意义                                                                                                                                                                       |
| ------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| PROPAGATION_MANDATORY     | 表示该方法必须运行在一个事务中。如果当前没有事务正在发生，将抛出一个异常                                                                                                   |
| PROPAGATION_NESTED        | 表示如果当前正有一个事务在进行中，则该方法应当运行在一个嵌套式事务中。被嵌套的事务可以独立于封装事务进行提交或回滚。如果封装事务不存在，行为就像PROPAGATION_REQUIRES一样。 |
| PROPAGATION_NEVER         | 表示当前的方法不应该在一个事务中运行。如果一个事务正在进行，则会抛出一个异常。                                                                                             |
| PROPAGATION_NOT_SUPPORTED | 表示该方法不应该在一个事务中运行。如果一个现有事务正在进行中，它将在该方法的运行期间被挂起                                                                                 |
| PROPAGATION_SUPPORTS      | 表示当前方法不需要事务性上下文，但是如果有一个事务已经在运行的话，它也可以在这个事务里运行                                                                                 |
| PROPAGATION_REQUIRES_NEW  | 表示当前方法必须在它自己的事务里运行。一个新的事务将被启动，而且如果有一个现有事务在运行的话，则将在这个方法运行期间被挂起。                                               |
| PROPAGATION_REQUIRES      | 表示当前方法必须在一个事务中运行。如果一个现有事务正在进行中，该方法将在那个事务中运行，否则就要开始一个新事务。                                                           |
传播规则回答了这样一个问题，就是一个新的事务应该被启动还是被挂起，或者是一个方法是否应该在事务性上下文中运行。

## spring 事务的隔离级别
声明式事务的第二个方面是隔离级别。隔离级别定义一个事务可能受其他并发事务活动活动影响的程度。另一种考虑一个事务的隔离级别的方式，是把它想象为那个事务对于事物处理数据的自私程度。

在一个典型的应用程序中，多个事务同时运行，经常会为了完成他们的工作而操作同一个数据。并发虽然是必需的，但是会导致一下问题：

脏读（Dirty read）-- 脏读发生在一个事务读取了被另一个事务改写但尚未提交的数据时。如果这些改变在稍后被回滚了，那么第一个事务读取的数据就会是无效的。
不可重复读（Nonrepeatable read）-- 不可重复读发生在一个事务执行相同的查询两次或两次以上，但每次查询结果都不相同时。这通常是由于另一个并发事务在两次查询之间更新了数据。
幻影读（Phantom reads）-- 幻影读和不可重复读相似。当一个事务（T1）读取几行记录后，另一个并发事务（T2）插入了一些记录时，幻影读就发生了。在后来的查询中，第一个事务（T1）就会发现一些原来没有的额外记录。
在理想状态下，事务之间将完全隔离，从而可以防止这些问题发生。然而，完全隔离会影响性能，因为隔离经常牵扯到锁定在数据库中的记录（而且有时是锁定完整的数据表）。侵占性的锁定会阻碍并发，要求事务相互等待来完成工作。

考虑到完全隔离会影响性能，而且并不是所有应用程序都要求完全隔离，所以有时可以在事务隔离方面灵活处理。因此，就会有好几个隔离级别。

| 隔离级别                   | 含义                                                                                                                                               |
| -------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |
| ISOLATION_DEFAULT          | 使用后端数据库默认的隔离级别                                                                                                                       |
| ISOLATION_READ_UNCOMMITTED | 允许读取尚未提交的更改。可能导致脏读、幻影读或不可重复读。                                                                                         |
| ISOLATION_READ_COMMITTED   | 允许从已经提交的并发事务读取。可防止脏读，但幻影读和不可重复读仍可能会发生。                                                                       |
| ISOLATION_REPEATABLE_READ  | 对相同字段的多次读取的结果是一致的，除非数据被当前事务本身改变。可防止脏读和不可重复读，但幻影读仍可能发生。                                       |
| ISOLATION_SERIALIZABLE     | 完全服从ACID的隔离级别，确保不发生脏读、不可重复读和幻影读。这在所有隔离级别中也是最慢的，因为它通常是通过完全锁定当前事务所涉及的数据表来完成的。 |

## spring mvc 的处理流程
SpringMVC执行流程:
1.用户发送请求至前端控制器DispatcherServlet
2.DispatcherServlet收到请求调用处理器映射器HandlerMapping。
3.处理器映射器根据请求url找到具体的处理器，生成处理器执行链HandlerExecutionChain(包括处理器对象和处理器拦截器)一并返回给DispatcherServlet。
4.DispatcherServlet根据处理器Handler获取处理器适配器HandlerAdapter执行HandlerAdapter处理一系列的操作，如：参数封装，数据格式转换，数据验证等操作
5.执行处理器Handler(Controller，也叫页面控制器)。
6.Handler执行完成返回ModelAndView
7.HandlerAdapter将Handler执行结果ModelAndView返回到DispatcherServlet
8.DispatcherServlet将ModelAndView传给ViewReslover视图解析器
9.ViewReslover解析后返回具体View
10.DispatcherServlet对View进行渲染视图（即将模型数据model填充至视图中）。
11.DispatcherServlet响应用户。

# 网络框架
## netty
## mina


# 服务器
## nginx


# 数据库
## mysql

# 数据库持久层
## mybatis
### mybatis 的1级2级缓存
### one-to-one， one-to-many， many-to-many

### mybatis mapper 配置文件
```
<!-- mapper 根标签 -->
<mapper namespace="com.fintecher.manage.mapper.OrderProcessRecordMapper"></mapper>

<!--   获取还款详情列表 一对一 一对多  -->
<resultMap id="paymentScheduleDetailModel" autoMapping="true"
           type="com.fintecher.manage.vo.PaymentScheduleDetailModel">
    <id property="id" column="id"/>
    <association property="paymentTotalCount" autoMapping="true"
                 column="{orderId=id}" select="getPaymentTotalCount"/>
    <collection property="paymentDetails" autoMapping="true"
                column="{orderId=id}" select="getPaymentDetails"/>
</resultMap>

<select id="getPaymentScheduleDetail" resultMap="paymentScheduleDetailModel">
    SELECT
        a.id,
        b.name as customerName,
        a.order_number as orderNumber,
        c.client_number as clientNumber
    from product_order a
       left join personal b on  a.personal_id = b.id
       left join personal_bank c on b.id = c.personal_id
    where a.id = #{orderId}
</select>

<select id="getPaymentDetails" resultType="com.fintecher.manage.entity.PaymentSchedule">
    SELECT
        a.id,
        a.periods,
        a.principal_surplus as principalSurplus,
        a.interest_surplus as interestSuplus,
        a.penalty_surplus as penaltySurplus
    FROM payment_schedule a
    WHERE a.order_id = #{orderId}
</select>

<select id="getPaymentTotalCount" resultType="com.fintecher.manage.entity.PaymentSchedule">
    SELECT
        sum(IFNULL(a.sum,0)),
        sum(IFNULL(a.penal_sum,0)) as penalSum,
        sum(IFNULL(a.interest_surplus,0)) as interestSuplus,
        sum(IFNULL(a.penalty_surplus,0)) as penaltySurplus
    FROM payment_schedule a
    WHERE a.order_id = #{orderId}
    GROUP BY a.order_id
</select>
    
<!-- 参数类型 -->    
<select id="getAuditRecord" parameterType="com.fintecher.manage.vo.ApproveHistoryParam"
resultType="com.fintecher.manage.vo.ApproveHistoryModel">
    SELECT
    o.id AS orderId,
    ....
    ORDER BY h.operate_time DESC
</select>
```

### mybatis mapper java
```
@Repository
public interface GoodsOrderMapper extends MyMapper<GoodsOrder> {

    @Select("select id,order_status,order_money,created_time from goods_order where user_id = #{user_id}")
    public List<GoodsOrder> getGoodsOrderState(@Param("user_id") long user_id);
}
```

# 分布式事务

# 设计模式

# UML

# 数据结构

# shell
## 删除某一应用所有进行
```
$ ps -ef | grep device* | grep -v grep | awk '{print $2}' |xargs kill -9
```

# 其他
## IaaS，PaaS，SaaS 的区别

 - IaaS：基础设施服务，Infrastructure-as-a-service
IaaS 是云服务的最底层，主要提供一些基础资源。它与 PaaS 的区别是，用户需要自己控制底层，实现基础设施的使用逻辑。例如：Amazon EC2，Digital Ocean，RackSpace Cloud

 - PaaS：平台服务，Platform-as-a-service
PaaS 提供软件部署平台（runtime），抽象掉了硬件和操作系统细节，可以无缝地扩展（scaling）。开发者只需要关注自己的业务逻辑，不需要关注底层。例如：Heroku，Google App Engine，OpenShift

 - SaaS：软件服务，Software-as-a-service
SaaS 是软件的开发、管理、部署都交给第三方，不需要关心技术问题，可以拿来即用。普通用户接触到的互联网服务，几乎都是 SaaS。例如：社交服务 Facebook / Twitter / Instagram

## 日志系统

## 在线系统和离线系统

# 大数据平台

## hadoop
Hadoop家族还包含各种开源组件，比如Yarn，Zookeeper，Hbase，Hive，Sqoop，Impala，Spark等

## 数据接入工具
批量数据：Flume，Logstash，NDC，Sqoop
实时数据：Strom，Spark streaming，kafka

## 数据存储
HBase，hadoop

# spring cloud
## spring cloud config

 一、config client 不能包括spring-cloud-config-server。如果config client服务包括 spring-cloud-config-server就可能导致config client变成一个config server
```
<!-- config client  -->
<dependency>
	<groupId>org.springframework.cloud</groupId>
	<artifactId>spring-cloud-starter-config</artifactId>
</dependency>

<!-- config server  -->
<dependency>
	<groupId>org.springframework.cloud</groupId>
	<artifactId>spring-cloud-config-server</artifactId>
</dependency>
```


# maven
## dependencies VS dependencyManagement
dependencies 即使在子项目中不写该依赖项，那么子项目仍然会从父项目中继承该依赖项（全部继承）
dependencyManagement 里只是声明依赖，并不实现引入，因此子项目需要显示的声明需要用的依赖。如果不在子项目中声明依赖，是不会从父项目中继承下来的；只有在子项目中写了该依赖项，并且没有指定具体版本，才会从父项目中继承该项，并且 version 和 scope 都读取自父 pom; 另外如果子项目中指定了版本号，那么会使用子项目中指定的jar版本。

## 消除多模块插件配置重复
```
<build>
  <pluginManagement>
    <plugins>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-compiler-plugin</artifactId>
        <version>2.5.1</version>
        <configuration>
          <source>1.8</source>
          <target>1.8</target>
          <encoding>UTF-8</encoding>
        </configuration>
      </plugin>
    </plugins>
  </pluginManagement>
</build>
```


  [1]: ./images/20171114162555512.jpg "20171114162555512"